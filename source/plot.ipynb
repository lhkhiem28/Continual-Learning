{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from libs import *\n",
    "\n",
    "from data import ImageDataset\n",
    "from models.models import PretextsCA\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\n",
    "    \"../ckps/HAM/PretextsCA/best.ptl\", \n",
    "    map_location = \"cuda\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(\n",
    "    data_dir = \"../datasets/HAM/train/\", \n",
    "    augment = True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, attn_features = [], []\n",
    "labels = []\n",
    "for i in tqdm.tqdm_notebook(range(len(train_dataset))):\n",
    "    image, label = train_dataset[i]\n",
    "\n",
    "    feature, attn_feature = model(image.cuda().unsqueeze(0))[0]\n",
    "    features.append(feature.squeeze(0).detach().cpu().numpy()), attn_features.append(attn_feature.squeeze(0).detach().cpu().numpy())\n",
    "    labels.append(label)\n",
    "\n",
    "features, attn_features = np.array(features), np.array(attn_features)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = TSNE(\n",
    "    n_components = 2, n_iter = 1000, \n",
    "    random_state = 23, \n",
    ")\n",
    "embedded_features, embedded_attn_features = embedder.fit_transform(features), embedder.fit_transform(attn_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    embedded_attn_features[:, 0], embedded_attn_features[:, 1], \n",
    "    c = labels, \n",
    "    s = 1, \n",
    ")\n",
    "\n",
    "plt.xlim([-110, 110])\n",
    "plt.ylim([-110, 110])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"../ckps/HAM/PretextsCA/attn_features\"):\n",
    "    os.makedirs(\"../ckps/HAM/PretextsCA/attn_features\")\n",
    "for c in range(7):\n",
    "    attn_features_c = attn_features[np.where(labels == c)[0]]\n",
    "    np.save(\"../ckps/HAM/PretextsCA/attn_features/attn_features_{}.npy\".format(c), attn_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
